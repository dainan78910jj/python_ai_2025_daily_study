{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df96090",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q python-dotenv\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597d003",
   "metadata": {},
   "source": [
    "Todays lab: Setting up the enviroment (cursor)\n",
    " \n",
    "Download cursor if you havent already.\n",
    "Create an account on openai\n",
    "Use the same version of python as i had in the lecture Python 3.12.10\n",
    "Do a couple of pip install before we start coding in the terminal:\n",
    "pip install requests\n",
    "pip install python-dotenv\n",
    "pip install gradio\n",
    "pip install pypdf\n",
    "pip install openai\n",
    "pip install openai-agents\n",
    "pip install -U ipykernel\n",
    "\n",
    "Open up cursor and download extension for Jupyter Notebook.\n",
    "Create a folder and call it \"Openai\" for example.\n",
    "Create a .env file and write this OPENAI_API_KEY=\n",
    "Create a new file and call it lab.ipynb and try out the stuff we did in the lecture(See lecture to get the code)\n",
    "When everything is successfully set up you can try this challenge:\n",
    "Create a (Django) website that a user should be able to ask any questions to openai and get the response in a website much like chatgpt. Dont worry about the esthetics, just make sure its working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f48b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9f76d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "env_value = os.getenv(\"DN\")\n",
    "\n",
    "print(env_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b44bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# 从.env文件中逐行读取每个变量，并逐一添加到程序环境变量列表中。\n",
    "\n",
    "# google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# grok_api_key = os.getenv(\"GROK_API_KEY\")\n",
    "# anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"API key loaded successfully {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API key not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c131106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# openai是程序包的名称，OpenAI是程序包中的一个类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b502748",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7d4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content': 'What is 2+2?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93d15b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24562518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f79e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have a 3-liter jug and a 5-liter jug, how can you measure out exactly 4 liters of water using only these two jugs?\n"
     ]
    }
   ],
   "source": [
    "question = \"Please propose a hard, challenging question to assess someones IQ. Respond only with the question.\"\n",
    "\n",
    "messages = [{'role': 'user', 'content': question}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03b20f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris. Would you like to know more about Paris or France in general?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://host.docker.internal:11434/v1')\n",
    "\n",
    "model_name = 'llama3.2'\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages)\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a8334fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is Paris."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'competitors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m display(Markdown(answer))\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcompetitors\u001b[49m\u001b[38;5;241m.\u001b[39mappend(model_name)\n\u001b[1;32m      4\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(answer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'competitors' is not defined"
     ]
    }
   ],
   "source": [
    "display(Markdown(answer))\n",
    "\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for competitors, answers in zip(competitors, answers):\n",
    "    print(f\"{competitors}: {answers}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
