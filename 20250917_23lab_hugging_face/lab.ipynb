{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2aa1cdd",
   "metadata": {},
   "source": [
    "Todays Lab 2025-09-22\n",
    " \n",
    "Implement a small script that (1) batches inputs with padding/truncation, (2) generates outputs with three decoding strategies (greedy, beam, sampling), (3) runs simple automatic checks on the outputs, and (4) times single vs. small-batch runs — all locally on CPU.\n",
    " \n",
    "Use this model & setup:\n",
    " \n",
    "- Model: google/flan-t5-base\n",
    " \n",
    "- Run on CPU only.\n",
    " \n",
    "- Tokenization must use padding=True, truncation=True, and your chosen max_length (justify by comment in code).\n",
    " \n",
    "- For generation use the same max_new_tokens across all strategies so results are comparable.\n",
    " \n",
    " \n",
    "Fixed prompt set (use these exact 12 prompts)\n",
    " \n",
    "Rewrite (4)\n",
    "1) Rewrite the sentence in simpler English. End with a period. Sentence: 'Python’s clear syntax helps beginners focus on problem-solving.' Output:\n",
    "2) Rewrite the sentence in simpler English. End with a period. Sentence: 'Version control lets teams track changes and work safely together.' Output:\n",
    "3) Rewrite the sentence in simpler English. End with a period. Sentence: 'Preprocessing text often includes lowercasing and removing extra spaces.' Output:\n",
    "4) Rewrite the sentence in simpler English. End with a period. Sentence: 'Short prompts run faster on CPU because attention scales with length.' Output:\n",
    " \n",
    "Explain (4)\n",
    "5) Explain in one sentence what a learning rate does. End with a period.\n",
    "6) Explain in one sentence what an API key is used for. End with a period.\n",
    "7) Explain in one sentence what a unit test checks. End with a period.\n",
    "8) Explain in one sentence what a tokenizer does in NLP. End with a period.\n",
    " \n",
    "Summarize (4)\n",
    "9) Summarize in one sentence: 'Pipelines bundle tokenization, the model, and decoding. They are great for quick demos on CPU.' Output:\n",
    "10) Summarize in one sentence: 'Batching several prompts can improve throughput. Padding and masks keep shapes compatible.' Output:\n",
    "11) Summarize in one sentence: 'Beam search is deterministic and often fluent. Sampling adds creativity but may drift.' Output:\n",
    "12) Summarize in one sentence: 'SentencePiece and WordPiece split text into subwords. This keeps vocabulary small and improves coverage.' Output:\n",
    " \n",
    " \n",
    "A) Batch tokenization (padding & truncation)\n",
    " \n",
    "- Batch all 12 prompts (you may prepend a short instruction like Respond in one sentence: if you want).\n",
    " \n",
    "- Tokenize with padding=True, truncation=True, and max_length you choose (briefly comment in code why).\n",
    " \n",
    "- Print:\n",
    "input_ids.shape and attention_mask.shape\n",
    "The tokenizer’s pad token id\n",
    "(Optional) Print the last row of attention_mask to show 1s (real tokens) vs 0s (padding).\n",
    " \n",
    " \n",
    "B) Decode the same batch three ways\n",
    "Run generation for the exact same tokenized batch with these strategies and print outputs for each prompt:\n",
    " \n",
    "- Greedy: do_sample=False, num_beams=1\n",
    " \n",
    "- Beam: do_sample=False, num_beams = 3 or 5 (pick one and note it in a comment)\n",
    " \n",
    "- Sampling: do_sample=True with your chosen temperature (≈0.7–0.9) and top_p (≈0.8–0.95)\n",
    " \n",
    "For each prompt, print three one-liners labeled [Greedy], [Beam], [Sample]. Keep them on separate lines or in a simple table.\n",
    " \n",
    "C) Automatic checks (programmatic, no prose)\n",
    "Write functions to check each generated line (no manual judging):\n",
    " \n",
    "1. One sentence? (exactly one terminal punctuation among . ! ?)\n",
    " \n",
    "2. Ends with a period?\n",
    " \n",
    "3. Word count window (choose a window, e.g., 8–24 words)\n",
    " \n",
    "4. Repetition flag (detect repeated bigrams/trigrams or obvious loops)\n",
    " \n",
    "Compute, per strategy (Greedy/Beam/Sampling):\n",
    " \n",
    "- Constraint pass-rate = % that pass checks 1+2+3\n",
    " \n",
    "- Avg. word count (and optionally std dev)\n",
    " \n",
    "- % with repetition (from check 4)\n",
    " \n",
    "Print a compact summary table to the console (one row per strategy).\n",
    " \n",
    "(Optional) Add a simple on-topic keyword flag per prompt if you want; otherwise skip.\n",
    " \n",
    " \n",
    "D) Tiny timing\n",
    "Measure on CPU with time.perf_counter():\n",
    "- Single input: tokenize → generate for 1 representative prompt (use the same max_new_tokens).\n",
    "- Small batch: tokenize → generate for a batch (use all 12 prompts, or duplicate them once).\n",
    " \n",
    "Print two numbers (seconds, 3 decimals):\n",
    "Single input: ~Xs\n",
    "Small batch : ~Ys\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8dc6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_sentences = [\n",
    "    'Python’s clear syntax helps beginners focus on problem-solving.',\n",
    "    'Version control lets teams track changes and work safely together.',\n",
    "    'Preprocessing text often includes lowercasing and removing extra spaces.',\n",
    "    'Short prompts run faster on CPU because attention scales with length.'   \n",
    "]\n",
    "\n",
    "explain_sentences = [\n",
    "    'what a learning rate does. End with a period.',\n",
    "    'what an API key is used for. End with a period.',\n",
    "    'what a unit test checks. End with a period.',\n",
    "    'what a tokenizer does in NLP. End with a period.'\n",
    "]\n",
    "\n",
    "summarize_sentences = [\n",
    "    'Pipelines bundle tokenization, the model, and decoding. They are great for quick demos on CPU.',\n",
    "    'Batching several prompts can improve throughput. Padding and masks keep shapes compatible.',\n",
    "    'Beam search is deterministic and often fluent. Sampling adds creativity but may drift.',\n",
    "    'SentencePiece and WordPiece split text into subwords. This keeps vocabulary small and improves coverage.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581c131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(inputs):\n",
    "    import re\n",
    "    from collections import Counter\n",
    "    \n",
    "    strategies = ['Greedy', 'Beam', 'Sample']\n",
    "    results = {}\n",
    "    \n",
    "    for i, strategy in enumerate(strategies):\n",
    "        outputs = inputs[i]\n",
    "        total = len(outputs)\n",
    "        \n",
    "        # Counters for checks\n",
    "        one_sentence_count = 0\n",
    "        ends_with_period_count = 0\n",
    "        word_count_window_count = 0\n",
    "        repetition_count = 0\n",
    "        \n",
    "        word_counts = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            # Check 1: One sentence? (exactly one terminal punctuation among . ! ?)\n",
    "            terminal_punctuation = len(re.findall(r'[.!?]', output))\n",
    "            if terminal_punctuation == 1:\n",
    "                one_sentence_count += 1\n",
    "            \n",
    "            # Check 2: Ends with a period?\n",
    "            if output.strip().endswith('.'):\n",
    "                ends_with_period_count += 1\n",
    "            \n",
    "            # Check 3: Word count window (choose a window, e.g., 8–24 words)\n",
    "            words = output.strip().split()\n",
    "            word_count = len(words)\n",
    "            word_counts.append(word_count)\n",
    "            if 8 <= word_count <= 24:\n",
    "                word_count_window_count += 1\n",
    "            \n",
    "            # Check 4: Repetition flag (detect repeated bigrams/trigrams or obvious loops)\n",
    "            has_repetition = False\n",
    "            words = [w.strip('.,!?;') for w in words]  # Clean words for repetition check\n",
    "            \n",
    "            # Check for repeated bigrams\n",
    "            if len(words) >= 4:  # Need at least 4 words to have 2 bigrams\n",
    "                bigrams = [tuple(words[j:j+2]) for j in range(len(words)-1)]\n",
    "                bigram_counts = Counter(bigrams)\n",
    "                if any(count > 1 for count in bigram_counts.values()):\n",
    "                    has_repetition = True\n",
    "            \n",
    "            # Check for repeated trigrams if not already flagged\n",
    "            if not has_repetition and len(words) >= 6:  # Need at least 6 words to have 2 trigrams\n",
    "                trigrams = [tuple(words[j:j+3]) for j in range(len(words)-2)]\n",
    "                trigram_counts = Counter(trigrams)\n",
    "                if any(count > 1 for count in trigram_counts.values()):\n",
    "                    has_repetition = True\n",
    "            \n",
    "            if has_repetition:\n",
    "                repetition_count += 1\n",
    "        \n",
    "        # Compute metrics\n",
    "        constraint_pass_rate = ((one_sentence_count + ends_with_period_count + word_count_window_count) / (3 * total)) * 100\n",
    "        avg_word_count = sum(word_counts) / len(word_counts) if word_counts else 0\n",
    "        repetition_percentage = (repetition_count / total) * 100\n",
    "        \n",
    "        results[strategy] = {\n",
    "            'constraint_pass_rate': constraint_pass_rate,\n",
    "            'avg_word_count': avg_word_count,\n",
    "            'repetition_percentage': repetition_percentage\n",
    "        }\n",
    "    \n",
    "    # Print a compact summary table to the console (one row per strategy)\n",
    "    print(f\"{'Strategy':<10} {'Pass Rate (%)':<15} {'Avg Words':<12} {'Repetition (%)':<15}\")\n",
    "    print(\"-\" * 55)\n",
    "    for strategy in strategies:\n",
    "        pass_rate = results[strategy]['constraint_pass_rate']\n",
    "        avg_words = results[strategy]['avg_word_count']\n",
    "        repetition = results[strategy]['repetition_percentage']\n",
    "        print(f\"{strategy:<10} {pass_rate:<15.2f} {avg_words:<12.2f} {repetition:<15.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3afb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single input: ~28.817s\n",
      "Small batch: ~0.006s\n",
      "input_ids shape: torch.Size([12, 37])\n",
      "attention_mask shape: torch.Size([12, 37])\n",
      "Pad token id : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Python’s clear syntax helps beginners focus on problem-solving.',\n",
       "  'Version control lets teams track changes and work safely together.',\n",
       "  'Preprocessing text often includes lowercasing and removing extraspaces.',\n",
       "  'Short prompts run faster on CPU because attention scales with length.',\n",
       "  \"a student's rate of learning\",\n",
       "  'a key to access a database',\n",
       "  'a unit test is a test of a unit.',\n",
       "  'a tokenizer is a digitized representation of a number',\n",
       "  'Use pipelines to test your code.',\n",
       "  'Use a rotary cutter to cut shapes.',\n",
       "  'Be aware of the benefits of beam search.',\n",
       "  'Use SentencePiece and WordPiece to split text into subwords.'],\n",
       " ['Python’s clear syntax helps beginners focus on problem-solving.',\n",
       "  'Version control lets teams track changes and work safely together.',\n",
       "  'Preprocessing text often includes lowercasing and removing extraspaces.',\n",
       "  'Short prompts run faster on CPU because attention scales with length.',\n",
       "  'The rate at which a student learns a new skill is called the rate at which a student learns a new skill.',\n",
       "  'API key is used for access control.',\n",
       "  'what a unit test looks like.',\n",
       "  'tokenizes a data set',\n",
       "  'Go to https://www.pipelines.com/ in a web browser. Go to https://www.pipelines.com in a web browser. Go to https://www.pipelines.com in a web browser. Go to https://www.pipelines.com in a web browser',\n",
       "  'Set up a batch of prompts. Set up a batch of masks. Set up a batch of masks. Set up a batch of masks. Set up a batch of masks. Set up a batch of masks. Set up a batch of masks. Set',\n",
       "  'Be aware that beam search is deterministic and often fluent. Be aware that sampling adds creativity but may drift. Be aware that beam search is deterministic and often fluent. Be aware that sampling adds creativity but may drift. Be aware that beam search is determin',\n",
       "  'Use SentencePiece and WordPiece to split text into subwords.'],\n",
       " ['Python’s clear syntax helps beginners focus on problem-solving.',\n",
       "  'Version control lets teams track changes and work safely together.',\n",
       "  'Preprocessing text often includes lowercasing and removing extraspaces.',\n",
       "  'Short prompts run faster on CPU because attention scales with length.',\n",
       "  'a student pauses his or her cell phone for a few minutes.',\n",
       "  'an input key',\n",
       "  'the properties of a gas',\n",
       "  'creates a digit',\n",
       "  'Plug in pipelines to your existing code.',\n",
       "  'Create a batch of prompts.',\n",
       "  'Seek a beam search.',\n",
       "  'Open SentencePiece and WordPiece.'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "token_output = tokenizer(\n",
    "    [f\"Rewrite the sentence in simpler English. End with a period. Sentence: {s}\" for s in rewrite_sentences] +\n",
    "    [f\"Explain in one sentence: {s}\" for s in explain_sentences] +\n",
    "    [f\"Summarize in one sentence: {s}\" for s in summarize_sentences], \n",
    "    return_tensors=\"pt\", \n",
    "    padding=True, \n",
    "    truncation=True, \n",
    "    max_length=96\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#Greedy decoding\n",
    "g = model.generate(\n",
    "    **token_output,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=False,\n",
    "    num_beams=1 \n",
    ")\n",
    "\n",
    "#Beam search\n",
    "b = model.generate(\n",
    "    **token_output,\n",
    "    max_new_tokens = 64,\n",
    "    do_sample = False,\n",
    "    num_beams=5 # 3 or 5\n",
    ")\n",
    "\n",
    "# Sampling\n",
    "s = model.generate(\n",
    "    **token_output,\n",
    "    max_new_tokens = 64,\n",
    "    do_sample = True,\n",
    "    temperature=0.8, \n",
    "    top_p=0.9, \n",
    "    num_return_sequences = 1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "res = (\n",
    "    tokenizer.batch_decode(g, skip_special_tokens=True), \n",
    "    tokenizer.batch_decode(b, skip_special_tokens=True),\n",
    "    tokenizer.batch_decode(s, skip_special_tokens=True),\n",
    ")\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Single input: ~{(t1-t0):.3f}s\")\n",
    "print(f\"Small batch: ~{(t2-t1):.3f}s\")\n",
    "\n",
    "print(\"input_ids shape:\", token_output.input_ids.shape) #[B, L]\n",
    "print(\"attention_mask shape:\", token_output.attention_mask.shape)\n",
    "print(\"Pad token id :\", tokenizer.pad_token_id)\n",
    "\n",
    "# check_res = check(res)\n",
    "\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
